{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 as bs\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def navigate_page(main_url,page_url,nav_tag,nav_tag_class):\n",
    "    url_s = str(page_url)\n",
    "    driver = webdriver.Firefox(executable_path=\"geckodriver.exe\")\n",
    "    #r=requests.get(url_s)\n",
    "    driver.get(url_s)\n",
    "    page_src = driver.page_source\n",
    "    s = BeautifulSoup(page_src, 'lxml')\n",
    "    l=[]\n",
    "    #Added bellow 3 lines to work pages which doesn't have navigation\n",
    "    if(nav_tag =='NA' or nav_tag == 'na' or nav_tag_class == 'na' or nav_tag_class == 'na'):\n",
    "        l.append(page_url)\n",
    "        return list(l)\n",
    "    for paragraph in s.find_all(str(nav_tag), class_=str(nav_tag_class)):\n",
    "        #print(paragraph)\n",
    "        for a in paragraph(\"a\"):\n",
    "            if \"http\" in a['href']:\n",
    "                l.append(a['href'])\n",
    "            if \"http\" not in a['href'] and a['href']:\n",
    "                l.append(main_url+a['href'])\n",
    "    driver.close()\n",
    "    return l\n",
    "\n",
    "def getproductlink(main_url,page_url,tag,tag_class,sub_tag,sub_tag_class,rt_tag,rt_class,rc_tag,rc_class):\n",
    "    try:\n",
    "        #data=requests.get(page_url)\n",
    "        #print(\"Page Title is : %s\" %driver.title)\n",
    "        driver = webdriver.Firefox(executable_path=\"geckodriver.exe\")\n",
    "        #r=requests.get(url_s)\n",
    "        driver.get(page_url)\n",
    "        page_src = driver.page_source\n",
    "    except Exception as error:\n",
    "        driver.close()\n",
    "        print('error: %s' %error)\n",
    "        print(\"Couldn't access url at indivisual_product_links.py\")\n",
    "\n",
    "    try:\n",
    "        soup = BeautifulSoup(page_src, 'lxml')\n",
    "        time.sleep(2)\n",
    "        driver.close()\n",
    "    except Exception as error:\n",
    "        driver.close()\n",
    "        print(\"Couldn't access page source at indivisual_product_links.py\")\n",
    "        print(error)\n",
    "    try:\n",
    "        tag_l = soup.find_all(str(tag),{\"class\":str(tag_class)})\n",
    "        st = '\\n\\n'.join(str(s) for s in tag_l)\n",
    "        lin = BeautifulSoup(str(st),'html.parser')\n",
    "        if tag_l:\n",
    "            link = lin.find_all(str(sub_tag),{\"class\":str(sub_tag_class)})\n",
    "    except:\n",
    "        print(\"Tag/link not found. Probable tag/class-mismatch error.\")\n",
    "        driver.close()\n",
    "    try:\n",
    "        l = []\n",
    "        if link:\n",
    "            for i in link:\n",
    "                review = []\n",
    "                revt = i.find_all(str(rt_tag),{\"class\":str(rt_class)})\n",
    "                if revt:\n",
    "                    if revt[0].find('p'):\n",
    "                        review.append(revt[0].find('p').text.strip())\n",
    "                    else:\n",
    "                        review.append(revt[0].text.strip())\n",
    "                revc = i.find_all(str(rc_tag),{\"class\":str(rc_class)})\n",
    "                if revc:\n",
    "                    if revc[0].find('p'):\n",
    "                        review.append(revc[0].find('p').text.strip(). rstrip('READ MORE'))\n",
    "                    else:\n",
    "                        review.append(revc[0].text.strip(). rstrip('READ MORE'))\n",
    "                l.append(review)\n",
    "                \n",
    "    except Exception as error:\n",
    "        print(error)\n",
    "        print(\"Cound not find the Sub_tag/link\")\n",
    "        driver.close()\n",
    "    #s=set(l)\n",
    "    j=0\n",
    "    if l:\n",
    "        for i in l:\n",
    "            #print(str(j)+\" : \"+i)\n",
    "            j += 1\n",
    "    return l\n",
    "\n",
    "def getproductlinks(main_url,page_url,tag,tag_class,sub_tag,sub_tag_class,rt_tag,rt_class,rc_tag,rc_class,nav_tag,nav_tag_class):\n",
    "    all_links=[]\n",
    "    prev_list=[main_url]\n",
    "    latest_links=navigate_page(main_url,page_url,nav_tag,nav_tag_class)\n",
    "    while \"https://www.snapdeal.comjavascript:void(0)\" in latest_links:\n",
    "            latest_links.remove(\"https://www.snapdeal.comjavascript:void(0)\")\n",
    "    while \"https://www.snapdeal.comjavascript:void(0);\" in latest_links:\n",
    "            latest_links.remove(\"https://www.snapdeal.comjavascript:void(0);\")\n",
    "    #print(latest_links)\n",
    "    repeat_cond = []\n",
    "    \n",
    "    while prev_list[-1]!=latest_links[-1]:\n",
    "        repeat_cond = prev_list\n",
    "        prev_list=latest_links\n",
    "        all_links.extend(latest_links)\n",
    "        latest_links=navigate_page(main_url,prev_list[-1],nav_tag,nav_tag_class)\n",
    "        while \"https://www.snapdeal.comjavascript:void(0)\" in latest_links:\n",
    "            latest_links.remove(\"https://www.snapdeal.comjavascript:void(0)\")\n",
    "        while \"https://www.snapdeal.comjavascript:void(0);\" in latest_links:\n",
    "            latest_links.remove(\"https://www.snapdeal.comjavascript:void(0);\")\n",
    "        if latest_links == repeat_cond:\n",
    "            break\n",
    "        if prev_list == repeat_cond:\n",
    "            break\n",
    "        #print(latest_links)\n",
    "        \n",
    "    #print(len(all_links))\n",
    "    all_links = list(set(all_links))\n",
    "    print(all_links)\n",
    "    \n",
    "    product_links=[]\n",
    "    for link in all_links:\n",
    "        product_links.extend(getproductlink(main_url,link,tag,tag_class,sub_tag,sub_tag_class,rt_tag,rt_class,rc_tag,rc_class))\n",
    "    return product_links\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Amazon\n",
    "main=\"https://www.amazon.com\"\n",
    "#url=str(\"https://www.amazon.com/COOLIFE-Luggage-Expandable-Suitcase-Spinner/product-reviews/B07JJ346MH/ref=cm_cr_dp_d_show_all_top?ie=UTF8&reviewerType=all_reviews\")\n",
    "url=str(\"https://www.amazon.com/COOLIFE-Luggage-Expandable-Suitcase-Spinner/product-reviews/B07JJ346MH/ref=cm_cr_getr_d_paging_btm_prev_32?ie=UTF8&pageNumber=32&reviewerType=all_reviews\")\n",
    "tag=str(\"div\")\n",
    "tag_c=str(\"a-section a-spacing-none reviews-content a-size-base\")\n",
    "sub_tag_class=str(\"a-section review\")\n",
    "sub_tag=str(\"div\")\n",
    "review_title_tag = \"a\"\n",
    "review_title_class = \"a-size-base a-link-normal review-title a-color-base review-title-content a-text-bold\"\n",
    "review_cont_tag = \"span\"\n",
    "review_cont_class = \"a-size-base review-text\"\n",
    "nav_tag = \"ul\"\n",
    "nav_class = \"a-pagination\"\n",
    "\n",
    "ans = getproductlinks(main,url,tag,tag_c,sub_tag,sub_tag_class,review_title_tag,review_title_class,review_cont_tag,review_cont_class,nav_tag,nav_class)\n",
    "print(\"----\")\n",
    "print(ans)\n",
    "k = 0\n",
    "for i,j in ans:\n",
    "    print(k)\n",
    "    k = k + 1\n",
    "    print(\"Title = \"+ i)\n",
    "    print(\"Content = \" +j)\n",
    "    print(\" \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
